{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Text Classification in Information Retrieval: A Comprehensive Approach with TF-IDF, Naive Bayes, Word Embeddings, LSA, and SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amirali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amirali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords # a library to tokenize input texts\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') # stopping word in English language\n",
    "\n",
    "import string # using to remove punctuation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from heapq import heappop, heappush, heapify\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class searchEngineNB:\n",
    "    def __init__(self ) -> None: # constructor of class\n",
    "        self.avrLen =0\n",
    "        self.postingList =[]\n",
    "        self.posPostingList=[]\n",
    "        self.negPostingList=[]\n",
    "        self.files=[] \n",
    "        self.numberOfDocuments = 0\n",
    "        self.numberOfPosDocuments = 0\n",
    "        self.numberOfNegDocuments = 0\n",
    "        self.tfIdfMatrix = []\n",
    "        self.tfIdfMatrixPos = []\n",
    "        self.tfIdfMatrixNeg = []\n",
    "        self.totalWords = 0\n",
    "        self.totalWordsPos = 0\n",
    "        self.totalWordsNeg = 0\n",
    "        self.naveBayes = {\n",
    "            \"pos\":{},\n",
    "            \"neg\":{}\n",
    "        }\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        # Stopwords set to ignore common words in English\n",
    "        self.stop = set(stopwords.words('english') + list(string.punctuation)) # all extra expression which should ignore\n",
    "\n",
    "        # structure of postingList : list of {word : nameOfWord , docs :[list of {doc:nameOfDocument , indexes: indexes of the word if this document}]}\n",
    "\n",
    "\n",
    "    # binary search to find a word in posting list\n",
    "    def searchPostingList(self, word,PostingList):\n",
    "\n",
    "        # Binary search to find a word in the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # - word: The word to search for in the posting list.\n",
    "\n",
    "        # Returns:\n",
    "        # - Index of the word in the posting list.\n",
    "\n",
    "        s= 0 \n",
    "        e = len(PostingList)\n",
    "        if e <=0 :\n",
    "            return 0\n",
    "        e-=1\n",
    "        while (1):\n",
    "            if (e-s < 2):\n",
    "                if (PostingList[e][\"word\"] < word):\n",
    "                    return e+1\n",
    "                if (PostingList[e][\"word\"] == word):\n",
    "                    return e\n",
    "                if (PostingList[s][\"word\"] >= word):\n",
    "                    return s\n",
    "\n",
    "                return e\n",
    "            mid = (s+e)/2\n",
    "            mid = int(mid)\n",
    "            if (word<PostingList[mid][\"word\"]):\n",
    "                e=mid\n",
    "            elif (word> PostingList[mid][\"word\"]):\n",
    "                s = mid\n",
    "            else :\n",
    "                return mid\n",
    "            \n",
    "        # {word:str, indexes:list(int)}\n",
    "    # binary search to find a word in each dictionary\n",
    "\n",
    "\n",
    "\n",
    "    def addToPostingList(self, tokenizedText: list[str],docIndex:int , PostingList,mode = \"main\"  ): # add tokenized word in posting list \n",
    "\n",
    "        # Add tokenized words to the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # - tokenizedText: List of tokenized words in a document.\n",
    "        # - docIndex: Index of the document.\n",
    "        # - title, author, B: Metadata of the document.\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "        if mode == \"main\" :\n",
    "            self.numberOfDocuments+=1\n",
    "        elif mode == \"pos\" :\n",
    "            self.numberOfPosDocuments+=1\n",
    "        else :\n",
    "            self.numberOfNegDocuments+=1\n",
    "        for i in range(len(tokenizedText)):\n",
    "            if mode == \"main\" :\n",
    "                self.totalWords+=1\n",
    "            elif mode == \"pos\" :\n",
    "                self.totalWordsPos+=1\n",
    "            else :\n",
    "                self.totalWordsNeg+=1\n",
    "            word = tokenizedText[i]\n",
    "            index = self.searchPostingList(word,PostingList) # find index of word in posting list\n",
    "            if (len(PostingList)>index): # check if index is not larger than posting list (if word is bigger that all words, search function returns len(postingList)+1)\n",
    "                if (PostingList[index][\"word\"] == word): # check if index is the index of the word\n",
    "                    if (PostingList[index][\"docs\"][-1][\"doc\"] == docIndex): # if we have already added the document index \n",
    "                        PostingList[index][\"docs\"][-1][\"indexes\"].append(i) # as we read tokens in order of their index, we need to add token in end of the list\n",
    "                        PostingList[index][\"docs\"][-1][\"tf\"]+=1\n",
    "                        PostingList[index][\"cf\"]+=1\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        PostingList[index][\"docs\"].append({\"doc\":docIndex,\"indexes\":[i], \"tf\":1  }) # if we have not already added the document and dou to the fact that they are read in order of their index, we can easily add append new one in end of the list \n",
    "                        PostingList[index][\"df\"]+=1\n",
    "                        PostingList[index][\"cf\"]+=1\n",
    "                        \n",
    "\n",
    "                else :\n",
    "                    PostingList[index:index]= [({\"word\":word ,\"df\":1 ,\"cf\":1 , \"docs\":[{\"doc\":docIndex,\"indexes\":[i], \"tf\":1  }]})] # word is bigger that all other words => we can append it to end of the list\n",
    "                                                    \n",
    "            else :\n",
    "                PostingList.append({\"word\":word ,\"df\":1 ,\"cf\":1 , \"docs\":[{\"doc\":docIndex,\"indexes\":[i], \"tf\":1 }]}) # we have not already added the word and dou to the fact that they are read in order of their index, we can easily add append new one in end of the list\n",
    "\n",
    "\n",
    "\n",
    "    def input (self, dataFrame, limit = -1,printDetails = False): # input paths of inputs\n",
    "\n",
    "\n",
    "        \n",
    "        totalLen = 0\n",
    "        data = dataFrame\n",
    "        self.data = data\n",
    "        self.numberOfDocuments = data.shape[0]\n",
    "        for i in range(self.numberOfDocuments ) :\n",
    "            if (i == limit ):break\n",
    "            file = data.iloc[i]\n",
    "            text = file[\"text\"] # read the file\n",
    "            # tokenize text and ignore stopping words using nltk library \n",
    "            tokenizedText = [word for word in word_tokenize(text.lower(),preserve_line=False) if word not in self.stop] \n",
    "            printDetails and print (f'document {i+1} tokenized : {tokenizedText}')\n",
    "            totalLen+=len(tokenizedText)\n",
    "            # print(tokenizedText)\n",
    "            self.addToPostingList(tokenizedText , i+1 , self.postingList) # i indicates to index of document we are reading\n",
    "            if file['rating'] >5:\n",
    "                self.addToPostingList(tokenizedText , file[\"ID\"]+1 , self.posPostingList,mode=\"pos\") # i indicates to index of document we are reading\n",
    "            else:\n",
    "                self.addToPostingList(tokenizedText , file[\"ID\"]+1 , self.negPostingList,mode=\"neg\") # i indicates to index of document we are reading\n",
    "\n",
    "        self.avrLen = totalLen/self.numberOfDocuments\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def trainNaveBayes (self):\n",
    "        # this function trans naive byes to predict class of the queries.\n",
    "\n",
    "        self.naveBayes = { # clear previous data\n",
    "            \"pos\":{},\n",
    "            \"neg\":{}\n",
    "        }\n",
    "\n",
    "        totalNumberOfTerms = len(self.postingList) # B\n",
    "        self.negDiv = (self.totalWordsNeg+ totalNumberOfTerms) \n",
    "        self.posDiv = (self.totalWordsPos+ totalNumberOfTerms)\n",
    "\n",
    "        for term in self.posPostingList: # find probabilities of positive class words\n",
    "            word = term[\"word\"]\n",
    "            cf = term[\"cf\"]\n",
    "            self.naveBayes[\"pos\"][word] = np.log(cf / self.posDiv)\n",
    "             \n",
    "        for term in self.negPostingList:# find probabilities of negative class words\n",
    "            word = term[\"word\"]\n",
    "            cf = term[\"cf\"]\n",
    "            self.naveBayes[\"neg\"][word] = np.log(cf / self.negDiv)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    def query (self, q ,printDetails=False ): # input the query and predict its class\n",
    "        q = str(q)\n",
    "        tokenizedQuery= [word for word in word_tokenize(q.lower(),preserve_line=False) if word not in self.stop] \n",
    "        PP = 0\n",
    "        PN = 0\n",
    "        TrainedDataPos = self.naveBayes[\"pos\"]\n",
    "        TrainedDataNeg = self.naveBayes[\"neg\"]\n",
    "        for term in tokenizedQuery:\n",
    "            try:\n",
    "                temp = TrainedDataPos[term]\n",
    "                PP+=temp\n",
    "                printDetails and print (f'word {term} exists in pos with value {temp}')\n",
    "            except:\n",
    "                PP+= np.log(1/self.posDiv)\n",
    "\n",
    "            try:\n",
    "                temp = TrainedDataNeg[term]\n",
    "                PN+=temp\n",
    "                printDetails and print (f'word {term} exists in neg with value {temp}')\n",
    "            except:\n",
    "                PN+= np.log(1/self.negDiv)\n",
    "            # PP+= np.log(1/self.posDiv)\n",
    "            # PN+= np.log(1/self.negDiv)\n",
    "        printDetails and print(f'positive probability is {PP} and negative probability is {PN}')\n",
    "        return PP>=PN \n",
    "\n",
    "    def build (self):\n",
    "\n",
    "        # Build the index.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "        self.trainNaveBayes()\n",
    "        self.makeIDF()\n",
    "        self.makeTfIdfMatrix()\n",
    "\n",
    "    def makeIDF (self):\n",
    "\n",
    "        # Calculate IDF for terms in the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "\n",
    "        for item in self.postingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "        for item in self.posPostingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfPosDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "        for item in self.negPostingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfNegDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "\n",
    "    def makeTfIdfMatrix(self): # create to matrix tfIdf and tdIdfPm\n",
    "\n",
    "        #  Calculate TF-IDF matrices for documents.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "\n",
    "        self.tfIdfMatrix =  [[0]*self.numberOfDocuments for _ in range(len(self.postingList))]\n",
    "        self.tfIdfMatrixPos =  [[0]*self.numberOfPosDocuments for _ in range(len(self.posPostingList))]\n",
    "        self.tfIdfMatrixNeg =  [[0]*self.numberOfNegDocuments for _ in range(len(self.negPostingList))]\n",
    "        for indx in range(len(self.postingList)):\n",
    "            item = self.postingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrix[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "\n",
    "        for indx in range(len(self.posPostingList)):\n",
    "            item = self.posPostingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrixPos[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "\n",
    "        for indx in range(len(self.negPostingList)):\n",
    "            item = self.negPostingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrixNeg[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "                \n",
    "\n",
    "\n",
    "        self.tfIdfMatrix = np.array(self.tfIdfMatrix ,dtype=float)\n",
    "        self.tfIdfMatrixPos = np.array(self.tfIdfMatrixPos ,dtype=float)\n",
    "        self.tfIdfMatrixNeg = np.array(self.tfIdfMatrixNeg ,dtype=float)\n",
    "\n",
    "        \n",
    "        for doc in range(self.numberOfDocuments):\n",
    "            norm =  np.linalg.norm(self.tfIdfMatrix[:,doc])\n",
    "\n",
    "\n",
    "\n",
    "    def Test (self, dataFrame, limit = -1,printDetails = False): \n",
    "        \n",
    "        TP = FP = FN= TN = 0\n",
    "        data = dataFrame\n",
    "        numberOfDocuments = data.shape[0]\n",
    "        for i in range(numberOfDocuments ) :\n",
    "            if (i == limit ):break\n",
    "            file = data.iloc[i]\n",
    "            text = file[\"text\"] \n",
    "            rating = file[\"rating\"]\n",
    "            result = self.query(text)\n",
    "            if (rating > 5):\n",
    "                if result:\n",
    "                    TP +=1\n",
    "                else :\n",
    "                    FN +=1\n",
    "            else :\n",
    "                if result:\n",
    "                    FP +=1\n",
    "                else :\n",
    "                    TN +=1\n",
    "        \n",
    "        return {\n",
    "            \"TP\":TP,\n",
    "            \"TN\":TN,\n",
    "            \"FP\":FP,\n",
    "            \"FN\":FN,\n",
    "\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings, LSA, and SVM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class searchEngineLSA_SVM:\n",
    "    def __init__(self ) -> None: # constructor of class\n",
    "        self.avrLen =0\n",
    "        self.postingList =[]\n",
    "        self.posPostingList=[]\n",
    "        self.negPostingList=[]\n",
    "        self.files=[] \n",
    "        self.numberOfDocuments = 0\n",
    "        self.numberOfPosDocuments = 0\n",
    "        self.numberOfNegDocuments = 0\n",
    "        self.tfIdfMatrix = []\n",
    "        self.tfIdfMatrixPos = []\n",
    "        self.tfIdfMatrixNeg = []\n",
    "        self.totalWords = 0\n",
    "        self.totalWordsPos = 0\n",
    "        self.totalWordsNeg = 0\n",
    "        self.xTrain=[]\n",
    "        self.xTest=[]\n",
    "        self.yTest=[]\n",
    "        self.yTest=[]\n",
    "        self.naveBayes = {\n",
    "            \"pos\":{},\n",
    "            \"neg\":{}\n",
    "        }\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        # Stopwords set to ignore common words in English\n",
    "        self.stop = set(stopwords.words('english') + list(string.punctuation)) # all extra expression which should ignore\n",
    "\n",
    "        # structure of postingList : list of {word : nameOfWord , docs :[list of {doc:nameOfDocument , indexes: indexes of the word if this document}]}\n",
    "\n",
    "\n",
    "    # binary search to find a word in posting list\n",
    "    def searchPostingList(self, word,PostingList):\n",
    "\n",
    "        # Binary search to find a word in the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # - word: The word to search for in the posting list.\n",
    "\n",
    "        # Returns:\n",
    "        # - Index of the word in the posting list.\n",
    "\n",
    "        s= 0 \n",
    "        e = len(PostingList)\n",
    "        if e <=0 :\n",
    "            return 0\n",
    "        e-=1\n",
    "        while (1):\n",
    "            if (e-s < 2):\n",
    "                if (PostingList[e][\"word\"] < word):\n",
    "                    return e+1\n",
    "                if (PostingList[e][\"word\"] == word):\n",
    "                    return e\n",
    "                if (PostingList[s][\"word\"] >= word):\n",
    "                    return s\n",
    "\n",
    "                return e\n",
    "            mid = (s+e)/2\n",
    "            mid = int(mid)\n",
    "            if (word<PostingList[mid][\"word\"]):\n",
    "                e=mid\n",
    "            elif (word> PostingList[mid][\"word\"]):\n",
    "                s = mid\n",
    "            else :\n",
    "                return mid\n",
    "            \n",
    "        # {word:str, indexes:list(int)}\n",
    "    # binary search to find a word in each dictionary\n",
    "\n",
    "\n",
    "\n",
    "    def addToPostingList(self, tokenizedText: list[str],docIndex:int , PostingList,mode = \"main\"  ): # add tokenized word in posting list \n",
    "\n",
    "        # Add tokenized words to the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # - tokenizedText: List of tokenized words in a document.\n",
    "        # - docIndex: Index of the document.\n",
    "        # - title, author, B: Metadata of the document.\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "        if mode == \"main\" :\n",
    "            self.numberOfDocuments+=1\n",
    "        elif mode == \"pos\" :\n",
    "            self.numberOfPosDocuments+=1\n",
    "        else :\n",
    "            self.numberOfNegDocuments+=1\n",
    "        for i in range(len(tokenizedText)):\n",
    "            if mode == \"main\" :\n",
    "                self.totalWords+=1\n",
    "            elif mode == \"pos\" :\n",
    "                self.totalWordsPos+=1\n",
    "            else :\n",
    "                self.totalWordsNeg+=1\n",
    "            word = tokenizedText[i]\n",
    "            index = self.searchPostingList(word,PostingList) # find index of word in posting list\n",
    "            if (len(PostingList)>index): # check if index is not larger than posting list (if word is bigger that all words, search function returns len(postingList)+1)\n",
    "                if (PostingList[index][\"word\"] == word): # check if index is the index of the word\n",
    "                    if (PostingList[index][\"docs\"][-1][\"doc\"] == docIndex): # if we have already added the document index \n",
    "                        PostingList[index][\"docs\"][-1][\"indexes\"].append(i) # as we read tokens in order of their index, we need to add token in end of the list\n",
    "                        PostingList[index][\"docs\"][-1][\"tf\"]+=1\n",
    "                        PostingList[index][\"cf\"]+=1\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        PostingList[index][\"docs\"].append({\"doc\":docIndex,\"indexes\":[i], \"tf\":1  }) # if we have not already added the document and dou to the fact that they are read in order of their index, we can easily add append new one in end of the list \n",
    "                        PostingList[index][\"df\"]+=1\n",
    "                        PostingList[index][\"cf\"]+=1\n",
    "                        \n",
    "\n",
    "                else :\n",
    "                    PostingList[index:index]= [({\"word\":word ,\"df\":1 ,\"cf\":1 , \"docs\":[{\"doc\":docIndex,\"indexes\":[i], \"tf\":1  }]})] # word is bigger that all other words => we can append it to end of the list\n",
    "                                                    \n",
    "            else :\n",
    "                PostingList.append({\"word\":word ,\"df\":1 ,\"cf\":1 , \"docs\":[{\"doc\":docIndex,\"indexes\":[i], \"tf\":1 }]}) # we have not already added the word and dou to the fact that they are read in order of their index, we can easily add append new one in end of the list\n",
    "\n",
    "\n",
    "\n",
    "    def input (self, dataFrameTrain , dataFrameTest,buildPostingList = False, limit = -1,printDetails = False): # input paths of inputs\n",
    "\n",
    "        # Input method to read documents from specified file CSV.\n",
    "\n",
    "        # Parameters:\n",
    "        # - dataFrame: List of file paths.\n",
    "        # - limit: Limit the number of documents to read (default: -1 means read all).\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "\n",
    "        totalLen = 0\n",
    "        data = dataFrameTrain.iloc[:limit]\n",
    "        self.datasetTest = dataFrameTest.iloc[:limit]\n",
    "        self.dataset = data\n",
    "\n",
    "        self.xTrain = dataFrameTrain[\"text\"].to_list()[:limit]\n",
    "        self.xTest = dataFrameTest[\"text\"].to_list()[:limit]\n",
    "        \n",
    "        self.yTrain = [\"pos\" if i>5 else \"neg\"  for i in dataFrameTrain[\"rating\"].to_list()[:limit]]\n",
    "        self.yTest = [\"pos\" if i>5 else \"neg\"  for i in dataFrameTest[\"rating\"].to_list()[:limit]]\n",
    "\n",
    "        if (buildPostingList):\n",
    "            self.numberOfDocuments = data.shape[0]\n",
    "            for i in range(self.numberOfDocuments ) :\n",
    "                if (i == limit ):break\n",
    "                file = data.iloc[i]\n",
    "                text = file[\"text\"] # read the file\n",
    "                # tokenize text and ignore stopping words using nltk library \n",
    "                tokenizedText = [word for word in word_tokenize(text.lower(),preserve_line=False) if word not in self.stop] \n",
    "                printDetails and print (f'document {i+1} tokenized : {tokenizedText}')\n",
    "                totalLen+=len(tokenizedText)\n",
    "                # print(tokenizedText)\n",
    "                self.addToPostingList(tokenizedText , i+1 , self.postingList) # i indicates to index of document we are reading\n",
    "                if file['rating'] >5:\n",
    "                    self.addToPostingList(tokenizedText , file[\"ID\"]+1 , self.posPostingList,mode=\"pos\") # i indicates to index of document we are reading\n",
    "                else:\n",
    "                    self.addToPostingList(tokenizedText , file[\"ID\"]+1 , self.negPostingList,mode=\"neg\") # i indicates to index of document we are reading\n",
    "\n",
    "            self.avrLen = totalLen/self.numberOfDocuments\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def word2vecModel(self,  vector_size=100, window=10, min_count=5, workers=4, sg=0):\n",
    "        model = Word2Vec(self.xTrain, vector_size=vector_size, window=window, min_count=min_count, workers=workers, sg=sg)\n",
    "        return model.wv\n",
    "\n",
    "    def gloveModel(self, glove_file, word2vec_output_file):\n",
    "        glove2word2vec(glove_file, word2vec_output_file)\n",
    "        model = KeyedVectors.load_word2vec_format(word2vec_output_file)\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def fastTextModel(self,   vector_size=100, window=5, min_count=5, workers=4, sg=1):\n",
    "        model = FastText(self.xTrain, vector_size=vector_size, window=window, min_count=min_count, workers=workers, sg=sg)\n",
    "        return model.wv\n",
    "\n",
    "    def makeDocumentEmbedding(self, doc, wVector):\n",
    "\n",
    "        words = [word for word in doc if word in wVector]\n",
    "        if not words:\n",
    "            return np.zeros(wVector.vector_size)\n",
    "        return np.mean(wVector[words], axis=0)\n",
    "    \n",
    "    def makeWordEmbeddings(self, wVector,mode=\"train\"):\n",
    "        data =  self.xTrain if mode == \"train\" else  self.xTest\n",
    "        return [self.makeDocumentEmbedding(doc, wVector) for doc in data]\n",
    "    \n",
    "    def lsaing(self, dataTrain, dataTest, n_components=100):\n",
    "        lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "        xTrainLSA = lsa.fit_transform(dataTrain)\n",
    "        xTestLsa = lsa.transform(dataTest)\n",
    "        return xTrainLSA, xTestLsa\n",
    "\n",
    "    def trainSvmClassifier(self,dataTrain, C=1.0, kernel='linear', gamma='auto'): # dataTrain can be embedding of terms\n",
    "        svmClassifier = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "        svmClassifier.fit(dataTrain, self.yTrain)\n",
    "        return svmClassifier\n",
    "\n",
    "\n",
    "\n",
    "    def Test (self,classifier,dataTest): \n",
    "        TP = TN = FP = FN = 0\n",
    "\n",
    "        yPredicted = classifier.predict(dataTest)\n",
    "        for i in range(len(yPredicted)):\n",
    "            mainLabel = self.yTest[i] == \"pos\"\n",
    "            predictLabel = yPredicted[i] == \"pos\"\n",
    "            if (mainLabel ):\n",
    "                if predictLabel:\n",
    "                    TP +=1\n",
    "                else :\n",
    "                    FN +=1\n",
    "            else :\n",
    "                if predictLabel:\n",
    "                    FP +=1\n",
    "                else :\n",
    "                    TN +=1\n",
    "        \n",
    "        return {\n",
    "            \"TP\":TP,\n",
    "            \"TN\":TN,\n",
    "            \"FP\":FP,\n",
    "            \"FN\":FN,\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    def train(self,mode=\"word2vecModel\"):\n",
    "        modeDic={\n",
    "            \"word2vecModel\":self.word2vecModel,\n",
    "            \"gloveModel\":self.gloveModel,\n",
    "            \"fastTextModel\":self.fastTextModel,\n",
    "        }\n",
    "        trainer = modeDic[mode]\n",
    "        wVector = trainer()\n",
    "\n",
    "        # Create Word Embeddings\n",
    "        xTrainWordEmb = self.makeWordEmbeddings( wVector)\n",
    "        xTestWordEmb = self.makeWordEmbeddings( wVector,mode=\"test\")\n",
    "\n",
    "\n",
    "        # Apply LSA\n",
    "        xTrainLSA, xTestLsa = self.lsaing(xTrainWordEmb, xTestWordEmb)\n",
    "\n",
    "        # Train SVM Classifier\n",
    "        svmClassifier = self.trainSvmClassifier(xTrainLSA)\n",
    "\n",
    "        # Evaluate the Classifier\n",
    "        return self.Test(svmClassifier,xTrainLSA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def build (self):\n",
    "\n",
    "        # Build the index.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "        self.trainNaveBayes()\n",
    "        self.makeIDF()\n",
    "        self.makeTfIdfMatrix()\n",
    "\n",
    "    def makeIDF (self):\n",
    "\n",
    "        # Calculate IDF for terms in the posting list.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "\n",
    "        for item in self.postingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "        for item in self.posPostingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfPosDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "        for item in self.negPostingList:\n",
    "            item[\"idf\"] = np.log(self.numberOfNegDocuments) - np.log((item[\"df\"] or 1))\n",
    "\n",
    "\n",
    "    def makeTfIdfMatrix(self): # create to matrix tfIdf and tdIdfPm\n",
    "\n",
    "        #  Calculate TF-IDF matrices for documents.\n",
    "\n",
    "        # Parameters:\n",
    "        # None\n",
    "\n",
    "        # Returns:\n",
    "        # None\n",
    "\n",
    "        self.tfIdfMatrix =  [[0]*self.numberOfDocuments for _ in range(len(self.postingList))]\n",
    "        self.tfIdfMatrixPos =  [[0]*self.numberOfPosDocuments for _ in range(len(self.posPostingList))]\n",
    "        self.tfIdfMatrixNeg =  [[0]*self.numberOfNegDocuments for _ in range(len(self.negPostingList))]\n",
    "        for indx in range(len(self.postingList)):\n",
    "            item = self.postingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrix[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "\n",
    "        for indx in range(len(self.posPostingList)):\n",
    "            item = self.posPostingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrixPos[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "\n",
    "        for indx in range(len(self.negPostingList)):\n",
    "            item = self.negPostingList[indx]\n",
    "            idf = item[\"idf\"]\n",
    "            docs = item[\"docs\"]\n",
    "            for doc in docs:\n",
    "                self.tfIdfMatrixNeg[indx][doc[\"doc\"]-1]=doc[\"tf\"] * idf\n",
    "                \n",
    "\n",
    "\n",
    "        self.tfIdfMatrix = np.array(self.tfIdfMatrix ,dtype=float)\n",
    "        self.tfIdfMatrixPos = np.array(self.tfIdfMatrixPos ,dtype=float)\n",
    "        self.tfIdfMatrixNeg = np.array(self.tfIdfMatrixNeg ,dtype=float)\n",
    "\n",
    "        \n",
    "        for doc in range(self.numberOfDocuments):\n",
    "            norm =  np.linalg.norm(self.tfIdfMatrix[:,doc])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printResults(result , printDetails=False):\n",
    "    TP,TN,FP,FN = result[\"TP\"],result[\"TN\"],result[\"FP\"],result[\"FN\"]\n",
    "    print (\"                  Positive                 Negative           \")\n",
    "    print (\"       -------------------------------------------------------\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\" True  |      {0:8d}           |        {1:8d}           |\".format(result[\"TP\"], result[\"FP\"]))\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       -------------------------------------------------------\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\" False |      {0:8d}           |        {1:8d}           |\".format(result[\"TN\"], result[\"FN\"]))\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       |                         |                           |\")\n",
    "    print (\"       -------------------------------------------------------\")\n",
    "\n",
    "    accuracy = (TP + TN) / (TP+TN+FN+FP)\n",
    "    printDetails and print (f'accuracy : {accuracy}')\n",
    "    print ()\n",
    "\n",
    "    recall = (TP ) / (TP+FN)\n",
    "    printDetails and print (f'recall : {recall}')\n",
    "    print ()\n",
    "\n",
    "    precision = (TP) / (TP+FP)\n",
    "    printDetails and print (f'precision : {precision}')\n",
    "    print ()\n",
    "\n",
    "    F1 = (2*precision) / (precision + recall)\n",
    "    printDetails and print (f'F1 : {F1}')\n",
    "    print ()\n",
    "\n",
    "    if printDetails :\n",
    "        print (f'TP : {TP}')\n",
    "        print (f'TN : {TN}')\n",
    "        print (f'FP : {FP}')\n",
    "        print (f'FN : {FN}')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\" : accuracy,\n",
    "        \"recall\" : recall,\n",
    "        \"precision\" : precision,\n",
    "        \"F1\" : F1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='dataSets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Document Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dfPosTrain = pd.read_csv(f'{directory}/train_pos.csv').sort_values(\"ID\")\n",
    "dfNegTrain = pd.read_csv(f'{directory}/train_neg.csv').sort_values(\"ID\")\n",
    "\n",
    "dfPosTest = pd.read_csv(f'{directory}/test_pos.csv').sort_values(\"ID\")\n",
    "dfNegTest = pd.read_csv(f'{directory}/test_neg.csv').sort_values(\"ID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>Bromwell High is nothing short of brilliant. E...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>\"All the world's a stage and its people actors...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ID                                               text  \\\n",
       "0              0   0  Bromwell High is a cartoon comedy. It ran at t...   \n",
       "3611        3611   1  If you like adult comedy cartoons, like South ...   \n",
       "4722        4722   2  Bromwell High is nothing short of brilliant. E...   \n",
       "5833        5833   3  \"All the world's a stage and its people actors...   \n",
       "6944        6944   4  FUTZ is the only show preserved from the exper...   \n",
       "\n",
       "      rating  \n",
       "0          9  \n",
       "3611       7  \n",
       "4722       9  \n",
       "5833      10  \n",
       "6944       8  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPosTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>Robert DeNiro plays the most unbelievably inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>I saw the capsule comment said \"great acting.\"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>This fanciful horror flick has Vincent Price p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ID                                               text  \\\n",
       "0              0   0  Story of a man who has unnatural feelings for ...   \n",
       "3611        3611   1  Robert DeNiro plays the most unbelievably inte...   \n",
       "4722        4722   2  I saw the capsule comment said \"great acting.\"...   \n",
       "5833        5833   3  If I had not read Pat Barker's 'Union Street' ...   \n",
       "6944        6944   4  This fanciful horror flick has Vincent Price p...   \n",
       "\n",
       "      rating  \n",
       "0          3  \n",
       "3611       1  \n",
       "4722       1  \n",
       "5833       4  \n",
       "6944       4  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNegTrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>My boyfriend and I went to watch The Guardian....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>My yardstick for measuring a movie's watch-abi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>How many movies are there that you can think o...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>This movie was sadly under-promoted but proved...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ID                                               text  \\\n",
       "0              0   0  I went and saw this movie last night after bei...   \n",
       "3611        3611   1  My boyfriend and I went to watch The Guardian....   \n",
       "4722        4722   2  My yardstick for measuring a movie's watch-abi...   \n",
       "5833        5833   3  How many movies are there that you can think o...   \n",
       "6944        6944   4  This movie was sadly under-promoted but proved...   \n",
       "\n",
       "      rating  \n",
       "0         10  \n",
       "3611      10  \n",
       "4722       7  \n",
       "5833       7  \n",
       "6944      10  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPosTest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a pale imitation of 'Officer and a Gen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>It seems ever since 1982, about every two or t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>Wow, another Kevin Costner hero movie. Postman...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>Alas, another Costner movie that was an hour t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ID                                               text  \\\n",
       "0              0   0  Once again Mr. Costner has dragged out a movie...   \n",
       "3611        3611   1  This is a pale imitation of 'Officer and a Gen...   \n",
       "4722        4722   2  It seems ever since 1982, about every two or t...   \n",
       "5833        5833   3  Wow, another Kevin Costner hero movie. Postman...   \n",
       "6944        6944   4  Alas, another Costner movie that was an hour t...   \n",
       "\n",
       "      rating  \n",
       "0          2  \n",
       "3611       3  \n",
       "4722       3  \n",
       "5833       4  \n",
       "6944       4  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNegTest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWholeTrain = pd.concat(\n",
    "    (dfPosTrain,dfNegTrain),\n",
    "    # axis=0,\n",
    "    join=\"inner\",\n",
    "    ignore_index=True,\n",
    "    keys=None,\n",
    "    levels=None,\n",
    "    names=None,\n",
    "    verify_integrity=False,\n",
    "    copy=True,\n",
    ")\n",
    "\n",
    "dfWholeTest = pd.concat(\n",
    "    (dfPosTest,dfNegTest),\n",
    "    # axis=0,\n",
    "    join=\"inner\",\n",
    "    ignore_index=True,\n",
    "    keys=None,\n",
    "    levels=None,\n",
    "    names=None,\n",
    "    verify_integrity=False,\n",
    "    copy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>Bromwell High is nothing short of brilliant. E...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>\"All the world's a stage and its people actors...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>2771</td>\n",
       "      <td>12495</td>\n",
       "      <td>OK, I love bad horror. I especially love horro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>2772</td>\n",
       "      <td>12496</td>\n",
       "      <td>To be brutally honest... I LOVED watching Seve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2773</td>\n",
       "      <td>12497</td>\n",
       "      <td>I'm sure that the folks on the Texas/Louisiana...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>2774</td>\n",
       "      <td>12498</td>\n",
       "      <td>This film has the kernel of a really good stor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2775</td>\n",
       "      <td>12499</td>\n",
       "      <td>I went to the movie as a Sneak Preview in Aust...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     ID                                               text  \\\n",
       "0               0      0  Bromwell High is a cartoon comedy. It ran at t...   \n",
       "1            3611      1  If you like adult comedy cartoons, like South ...   \n",
       "2            4722      2  Bromwell High is nothing short of brilliant. E...   \n",
       "3            5833      3  \"All the world's a stage and its people actors...   \n",
       "4            6944      4  FUTZ is the only show preserved from the exper...   \n",
       "...           ...    ...                                                ...   \n",
       "24995        2771  12495  OK, I love bad horror. I especially love horro...   \n",
       "24996        2772  12496  To be brutally honest... I LOVED watching Seve...   \n",
       "24997        2773  12497  I'm sure that the folks on the Texas/Louisiana...   \n",
       "24998        2774  12498  This film has the kernel of a really good stor...   \n",
       "24999        2775  12499  I went to the movie as a Sneak Preview in Aust...   \n",
       "\n",
       "       rating  \n",
       "0           9  \n",
       "1           7  \n",
       "2           9  \n",
       "3          10  \n",
       "4           8  \n",
       "...       ...  \n",
       "24995       1  \n",
       "24996       1  \n",
       "24997       4  \n",
       "24998       2  \n",
       "24999       2  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWholeTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3611</td>\n",
       "      <td>1</td>\n",
       "      <td>My boyfriend and I went to watch The Guardian....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>My yardstick for measuring a movie's watch-abi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5833</td>\n",
       "      <td>3</td>\n",
       "      <td>How many movies are there that you can think o...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6944</td>\n",
       "      <td>4</td>\n",
       "      <td>This movie was sadly under-promoted but proved...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>2771</td>\n",
       "      <td>12495</td>\n",
       "      <td>CyberTracker is set in Los Angeles sometime in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>2772</td>\n",
       "      <td>12496</td>\n",
       "      <td>Eric Phillips (Don Wilson) is a secret service...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2773</td>\n",
       "      <td>12497</td>\n",
       "      <td>Plot Synopsis: Los Angeles in the future. Crim...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>2774</td>\n",
       "      <td>12498</td>\n",
       "      <td>Oh, dear! This has to be one of the worst film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2775</td>\n",
       "      <td>12499</td>\n",
       "      <td>This movie was sooo bad. It wasn't even funny ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     ID                                               text  \\\n",
       "0               0      0  I went and saw this movie last night after bei...   \n",
       "1            3611      1  My boyfriend and I went to watch The Guardian....   \n",
       "2            4722      2  My yardstick for measuring a movie's watch-abi...   \n",
       "3            5833      3  How many movies are there that you can think o...   \n",
       "4            6944      4  This movie was sadly under-promoted but proved...   \n",
       "...           ...    ...                                                ...   \n",
       "24995        2771  12495  CyberTracker is set in Los Angeles sometime in...   \n",
       "24996        2772  12496  Eric Phillips (Don Wilson) is a secret service...   \n",
       "24997        2773  12497  Plot Synopsis: Los Angeles in the future. Crim...   \n",
       "24998        2774  12498  Oh, dear! This has to be one of the worst film...   \n",
       "24999        2775  12499  This movie was sooo bad. It wasn't even funny ...   \n",
       "\n",
       "       rating  \n",
       "0          10  \n",
       "1          10  \n",
       "2           7  \n",
       "3           7  \n",
       "4          10  \n",
       "...       ...  \n",
       "24995       3  \n",
       "24996       3  \n",
       "24997       4  \n",
       "24998       1  \n",
       "24999       1  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWholeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'searchEngineNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SE \u001b[38;5;241m=\u001b[39m \u001b[43msearchEngineNB\u001b[49m()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# SE.input(dfWholeTrain.iloc[:10]  , printDetails=True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m SE\u001b[38;5;241m.\u001b[39minput(dfWholeTrain  , printDetails\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'searchEngineNB' is not defined"
     ]
    }
   ],
   "source": [
    "SE = searchEngineNB()\n",
    "# SE.input(dfWholeTrain.iloc[:10]  , printDetails=True)\n",
    "SE.input(dfWholeTrain  , printDetails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TF-IDF Vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE.makeIDF()\n",
    "SE.makeTfIdfMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSE\u001b[49m\u001b[38;5;241m.\u001b[39mtrainNaveBayes()\n\u001b[1;32m      2\u001b[0m SE\u001b[38;5;241m.\u001b[39mnaveBayes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SE' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "SE.trainNaveBayes()\n",
    "SE.naveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE.query(dfPosTest.iloc[1][\"text\"],printDetails=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE.query(dfNegTest.iloc[1][\"text\"],printDetails=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 9630, 'TN': 10999, 'FP': 1501, 'FN': 2870}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = SE.Test(dfWholeTest)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,TN,FP,FN = result[\"TP\"],result[\"TN\"],result[\"FP\"],result[\"FN\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Positive                 Negative           \n",
      "       -------------------------------------------------------\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      " True  |          9630           |            1501           |\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      "       -------------------------------------------------------\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      " False |         10999           |            2870           |\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      "       -------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review NaiveBayes Results :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.82516\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN) / (TP+TN+FN+FP)\n",
    "print (f'accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 0.7704\n"
     ]
    }
   ],
   "source": [
    "recall = (TP ) / (TP+FN)\n",
    "print (f'recall : {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.8651513790315336\n"
     ]
    }
   ],
   "source": [
    "precision = (TP) / (TP+FP)\n",
    "print (f'precision : {precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 : 1.0579323769624644\n"
     ]
    }
   ],
   "source": [
    "F1 = (2*precision) / (precision + recall)\n",
    "print (f'F1 : {F1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELSA = searchEngineLSA_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELSA.input(dfWholeTrain,  dfWholeTest )\n",
    "# rang= 10\n",
    "# SampleDataTrain  = pd.concat(\n",
    "#     (dfWholeTrain.iloc[:rang],dfNegTrain.iloc[:rang]),\n",
    "#     # axis=0,\n",
    "#     join=\"inner\",\n",
    "#     ignore_index=True,\n",
    "#     keys=None,\n",
    "#     levels=None,\n",
    "#     names=None,\n",
    "#     verify_integrity=False,\n",
    "#     copy=True,\n",
    "# )\n",
    "# SampleDataTest  = pd.concat(\n",
    "#     (dfWholeTest.iloc[:rang],dfNegTest.iloc[:rang]),\n",
    "#     # axis=0,\n",
    "#     join=\"inner\",\n",
    "#     ignore_index=True,\n",
    "#     keys=None,\n",
    "#     levels=None,\n",
    "#     names=None,\n",
    "#     verify_integrity=False,\n",
    "#     copy=True,\n",
    "# )\n",
    "# SELSA.input(SampleDataTrain , SampleDataTest, printDetails=True)\n",
    "# SampleDataTrain\n",
    "# SampleDataTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # modeDic={\n",
    "    #     \"word2vecModel\":self.word2vecModel,\n",
    "    #     \"gloveModel\":self.gloveModel,\n",
    "    #     \"fastTextModel\":self.fastTextModel,\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = SELSA.train(mode=\"word2vecModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 8398, 'TN': 7822, 'FP': 4677, 'FN': 4102}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Positive                 Negative           \n",
      "       -------------------------------------------------------\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      " True  |          8398           |            4677           |\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      "       -------------------------------------------------------\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      " False |          7822           |            4102           |\n",
      "       |                         |                           |\n",
      "       |                         |                           |\n",
      "       -------------------------------------------------------\n",
      "accuracy : 0.6488259530381215\n",
      "\n",
      "recall : 0.67184\n",
      "\n",
      "precision : 0.6422944550669216\n",
      "\n",
      "F1 : 0.9775171065493646\n",
      "\n",
      "TP : 8398\n",
      "TN : 7822\n",
      "FP : 4677\n",
      "FN : 4102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6488259530381215,\n",
       " 'recall': 0.67184,\n",
       " 'precision': 0.6422944550669216,\n",
       " 'F1': 0.9775171065493646}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printResults(result , printDetails=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
